# ê¸°ì¡´ ë‚´ê±°
import streamlit as st
import json
import torch
from transformers import BertTokenizerFast, BertForSequenceClassification
########################################################################
# í…œí”Œë¦¿ ê±°
import regex as re
from transformers import AutoTokenizer, AutoModelForSequenceClassification
#import string
import plotly.express as px
import pandas as pd
import nltk
from nltk.tokenize import sent_tokenize
from datetime import timedelta, datetime
from pytz import timezone
import title
nltk.download('punkt')

# Configure app page
st.set_page_config(page_title="Drug Classifier", layout= "wide", initial_sidebar_state="auto", page_icon="ğŸš¦")

import style
st.markdown(style.style, unsafe_allow_html=True)
st.markdown(style.textbox_style,unsafe_allow_html=True)
########################################################################################

title.header()
st.write('---')
st.subheader("ğŸš¦ ë§ˆì•½ ê¸€ ë¶„ë¥˜")


@st.cache(allow_output_mutation=True)
def load_model(model_name_or_path):
    tokenizer = BertTokenizerFast.from_pretrained(model_name_or_path)
    model = BertForSequenceClassification.from_pretrained(model_name_or_path)
    return tokenizer, model

# tokenizer, model = load_model("bert-base-multilingual-cased")
tokenizer, model = load_model("beomi/kcbert-base")
# text="ëˆ„êµ¬ë“ ì§€ ì•„ë™Â·ì²­ì†Œë…„ì´ìš©ìŒë€ë¬¼ì„ì„ ì•Œë©´ì„œ ì´ë¥¼ ì†Œì§€í•˜ì—¬ì„œëŠ” ì•„ë‹ˆëœë‹¤."
# st.write(text)
# tokenized_text = tokenizer.tokenize(text)


def prep_text(text):
    """
    function for preprocessing text
    """

    # remove trailing characters (\s\n) and convert to lowercase
    clean_sents = [] # append clean con sentences
    sent_tokens = sent_tokenize(str(text))
    for sent_token in sent_tokens:
        word_tokens = [str(word_token).strip().lower() for word_token in sent_token.split()]
        #word_tokens = [word_token for word_token in word_tokens if word_token not in punctuations]
        clean_sents.append(' '.join((word_tokens)))
    joined = ' '.join(clean_sents).strip(' ')
    joined = re.sub(r'`', "", joined)
    joined = re.sub(r'"', "", joined)
    return joined




# Form to recieve input text ### ì—¬ê¸°ë¥¼ ë¦¬ì…‹í˜•íƒœë¡œ ë°”ê¿€ ê±°ì„ 
# st.markdown("##### Text Input")
with st.form(key="my_form"):
    Text_entry = st.text_area(
        "Paste or type text in the box below (i.e., input)"
    )
    submitted = st.form_submit_button(label="ğŸ‘‰ ë¶„ë¥˜ !")

if submitted:

    # SDG labels list

    label_list = [
        'ğŸš¨â›”ï¸ğŸš«ğŸ”´ ë§ˆì•½ ê´€ë ¨ ê¸€ í™•ì‹¤',
        'ğŸ”µğŸŸ¦ğŸ”¹ğŸ”· ë§ˆì•½ ê´€ë ¨ ê¸€ ë¹„í•´ë‹¹'
    ]

    if Text_entry == "":
        st.warning(
            """ì…ë ¥ì´ í•„ìš”í•©ë‹ˆë‹¤.""",
            # icon="
        )

    elif Text_entry != "":

        # Pre-process text
        joined_clean_sents = prep_text(Text_entry)

        

        # tokenize pre-processed text
        # tokenizer_ = load_tokenizer()
        # tokenized_text = tokenizer_(joined_clean_sents, return_tensors="pt", truncation=True, max_length=512)
        tokenized_text = tokenizer(joined_clean_sents, return_tensors="pt", truncation=True, max_length=512)

        # predict pre-processed
        # model = load_model()
        text_logits = model(**tokenized_text).logits
        predictions = torch.softmax(text_logits, dim=1).tolist()[0]
        predictions = [round(a, 3) for a in predictions]

        # dictionary with label as key and percentage as value
        pred_dict = (dict(zip(label_list, predictions)))

        # sort 'pred_dict' by value and index the highest at [0]
        sorted_preds = sorted(pred_dict.items(), key=lambda x: x[1], reverse=True)

        # Make dataframe for plotly bar chart
        u, v = zip(*sorted_preds)
        x = list(u)
        y = list(v)
        df2 = pd.DataFrame()
        df2['SDG'] = x
        df2['Likelihood'] = y

        c1, c2, c3 = st.columns([2, 0.5, 1])

        with c1:
            st.markdown("##### ì˜ˆì¸¡ ê²°ê³¼")
            # plot graph of predictions
            fig = px.bar(df2, y="Likelihood", x="SDG") #, orientation="h")
            

            fig.update_layout(
                barmode='stack',
                template='ggplot2', #seaborn
                font=dict(
                    family="Arial",
                    size=20,
                    color="white"
                ),
                autosize=True, # False
                width=700,
                height=500,
                yaxis_title="ê°€ëŠ¥ì„±",
                xaxis_title="ë¶„ë¥˜",
                # legend_title="Topics"
            )

            fig.update_xaxes(tickangle=0, tickfont=dict(family='Arial', color='white', size=20))
            fig.update_yaxes(tickangle=0, tickfont=dict(family='Arial', color='white', size=20))
            fig.update_annotations(font_size=14)  # this changes y_axis, x_axis and subplot title font sizes

            # Plot
            st.plotly_chart(fig, use_container_width=False)

        with c3:
            st.header("")
            predicted = st.markdown("###### ì˜ˆì¸¡ëœ ê²°ê³¼ : " + str(sorted_preds[0][0]))
            Prediction_confidence = st.metric("ì˜ˆì¸¡ ì‹ ë¢°ë„", (str(round(sorted_preds[0][1] * 100, 1)) + "%"))
            
        st.success("ì„±ê³µì ìœ¼ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤!", icon="âœ…")
         
