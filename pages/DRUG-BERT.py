# ê¸°ì¡´ ë‚´ê±°
import streamlit as st
import json
import torch
from transformers import BertTokenizerFast, BertForSequenceClassification
########################################################################
# í…œí”Œë¦¿ ê±° (https://sadickam-sdg-classification-bert-main-qxg1gv.streamlit.app/)
# (https://github.com/sadickam/sdg-classification-bert/blob/main/main.py)
import regex as re
from transformers import AutoTokenizer, AutoModelForSequenceClassification
#import string
import plotly.express as px
import pandas as pd
import nltk
import random
from nltk.tokenize import sent_tokenize
from datetime import timedelta, datetime
from pytz import timezone
import title
nltk.download('punkt')

# Configure app page
st.set_page_config(page_title="Drug Classifier", layout= "wide", initial_sidebar_state="auto", page_icon="ğŸš¦")

import style
st.markdown(style.style, unsafe_allow_html=True)
# st.markdown(style.textbox_style,unsafe_allow_html=True)
########################################################################################

title.header()
st.write('---')
st.subheader("ğŸš¦ ë§ˆì•½ ê¸€ ë¶„ë¥˜")


@st.cache(allow_output_mutation=True)
def load_model(model_name_or_path):
    tokenizer = BertTokenizerFast.from_pretrained(model_name_or_path)
    model = BertForSequenceClassification.from_pretrained(model_name_or_path)
    return tokenizer, model

# tokenizer, model = load_model("bert-base-multilingual-cased")
tokenizer, model = load_model("beomi/kcbert-base")
# text="ëˆ„êµ¬ë“ ì§€ ì•„ë™Â·ì²­ì†Œë…„ì´ìš©ìŒë€ë¬¼ì„ì„ ì•Œë©´ì„œ ì´ë¥¼ ì†Œì§€í•˜ì—¬ì„œëŠ” ì•„ë‹ˆëœë‹¤."
# st.write(text)
# tokenized_text = tokenizer.tokenize(text)


def prep_text(text):
    """
    function for preprocessing text
    """

    # remove trailing characters (\s\n) and convert to lowercase
    clean_sents = [] # append clean con sentences
    sent_tokens = sent_tokenize(str(text))
    for sent_token in sent_tokens:
        word_tokens = [str(word_token).strip().lower() for word_token in sent_token.split()]
        #word_tokens = [word_token for word_token in word_tokens if word_token not in punctuations]
        clean_sents.append(' '.join((word_tokens)))
    joined = ' '.join(clean_sents).strip(' ')
    joined = re.sub(r'`', "", joined)
    joined = re.sub(r'"', "", joined)
    return joined



example_lst = ['ë§ˆì•½ ì¹¼êµ­ìˆ˜ ë§ˆì•½ê¹€ë°¥ ë§ˆì•½ë–¡ë³¶ì´ ì´ëŸ° ê°‘íŒ ì—†ì–´ì¡Œìœ¼ë©´ ì¢‹ê² ë‹¤',
                'ì•„ì£¼ ë»‘ê°€ë©´ ê°ë‹¹ ì•ˆë˜ê¸´í•©ë‹ˆë‹¤ë§Œ ì •ì‹ ì°¨ë¦¬ê³  ë³´ë©´ ë°°ë“œíŠ¸ë¦½ë„ ì¬ë°Œì–´ìš” ì¦ê¸°ì„¸ìš” ê·¸ëƒ¥ ë°°ë“œ íŠ¸ë¦½ì€ ì–‘ë³´ë‹¤ëŠ” ê·¸ ìˆœê°„ì˜ ì£¼ìœ„í™˜ê²½ ì˜í–¥ì„ ë§ì´ ë°›ëŠ”ê±° ê°™ìŠµë‹ˆë‹¤ ì €ë„ ë²ˆê²ªê³  ì§€ì¸ë„ ë²ˆê²ªì—ˆëŠ”ë° ê³µí†µì ì¸ íŠ¹ì§•ì€ í•˜ì´ ë„ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì–´ë–¤ ì¼ì— ëŒ€í•´ì„œ ë¶ˆì•ˆ',
                'ì˜¤í›„  ì•„ê³ ë¼ì—ì„œ ê°€ì ¸ì˜´   ì‰¬í•‘ì´ ê±¸ë¦¬ë ¤ë‚˜   ì•„ ì œë°œ ë§ˆì•½ êµ¬ì…í• ë•ŒëŠ” ë°°ì†¡ì‹œ ì„¸ê´€ ê²½ì°°ì— ê±¸ë ¤ë„ ë¬¸ì œ ì—†ì„ì •ë„ë¡œ ê³„íšì„ ì§œë¼ê³  ë³‘ì‹ ìƒˆë¼ì•¼ ê±¸ë¦´ì§€ ì•ˆê±¸ë¦´ì§€ë¥¼ ê±±ì •í•˜ì§€ë§ê³  ì§„ì§œ ë‡Œì— ë˜¥',
                'ì´ëŸ° ì´ì ì€ ì „ë¶€ íœ´ì‹ê³¼ ì¶©ë¶„í•œ ìˆ™ë©´ì´ë©´ ë‚˜ì•„ì§€ëŠ”ê±´ë° ë³‘ì‹ ê°™ì€ì˜ìƒí•˜ë‚˜ì˜¬ë ¤ì„œ  ëŒ€ë§ˆì´ˆ í¼ ë¯¸ì³¤ë‹¤ ì´ì§€ë„í•˜ëŠ”ìƒˆë¼ë“¤ì€ ì—†ê¸¸ë°”ë€ë‹¤ ê°€ì„œ ì³ìë¼'
        ]

platform_lst = ['íŠ¸ìœ„í„°', 'í…”ë ˆê·¸ë¨', 'ìœ íŠœë¸Œ' ,'DCì¸ì‚¬ì´ë“œ']
        
def reset():
    st.session_state.selection = 'Please Select'
        
example_num = random.randrange(0,4)
Text_entry = st.text_area("ì˜ˆì‹œ ë¬¸ì¥", example_lst[example_num])
submitted = st.button('ì˜ˆì‹œ ë¬¸ì¥ ì´ˆê¸°í™”', on_click=reset)

# Form to recieve input text ### ì—¬ê¸°ë¥¼ ë¦¬ì…‹í˜•íƒœë¡œ ë°”ê¿€ ê±°ì„ 
# st.markdown("##### Text Input")
# with st.form(key="my_form"):
#     Text_entry = st.text_area(
#         "Paste or type text in the box below (i.e., input)", max_chars=512
#     )
#     submitted = st.form_submit_button(label="ğŸ‘‰ ë¶„ë¥˜ !")

if 1 : # submitted:

    # SDG labels list

    label_list = [
        'ğŸ”µ ë§ˆì•½ ê´€ë ¨ ê¸€ ë¹„í•´ë‹¹',
        'ğŸ”´ ë§ˆì•½ ê´€ë ¨ ê¸€ í™•ì‹¤',
    ]

    if Text_entry == "":
        st.warning(
            """ì…ë ¥ì´ í•„ìš”í•©ë‹ˆë‹¤.""",
            # icon="
        )

    elif Text_entry != "":

        # Pre-process text
        joined_clean_sents = prep_text(Text_entry)

        

        # tokenize pre-processed text
        # tokenizer_ = load_tokenizer()
        # tokenized_text = tokenizer_(joined_clean_sents, return_tensors="pt", truncation=True, max_length=512)
        tokenized_text = tokenizer(joined_clean_sents, return_tensors="pt", truncation=True, max_length=512)

        # predict pre-processed
        # model = load_model()
        text_logits = model(**tokenized_text).logits
        predictions = torch.softmax(text_logits, dim=1).tolist()[0]
        predictions = [round(a, 3) for a in predictions]

        # dictionary with label as key and percentage as value
        pred_dict = (dict(zip(label_list, predictions)))

        # sort 'pred_dict' by value and index the highest at [0]
        sorted_preds = sorted(pred_dict.items(), key=lambda x: x[1], reverse=True)

        # Make dataframe for plotly bar chart
        u, v = zip(*sorted_preds)
        x = list(u)
        y = list(v)
        df2 = pd.DataFrame()
        df2['SDG'] = x
        df2['Likelihood'] = y

        c1, c2, c3 = st.columns([2, 0.5, 2])

        with c1:
            st.markdown("##### ì˜ˆì¸¡ ê²°ê³¼")
            # plot graph of predictions
    
            fig = px.bar(df2, y="Likelihood", x="SDG",
                          color = 'SDG',
                          color_discrete_map = {label_list[0]: '#172b9c',label_list[1]: '#b82d1d'}) #, 'versicolor': 'rgb(0,0,255)'})

                         # color_discrete_sequence= ['#b82d1d', '#172b9c']) #, orientation="h")


            fig.update_layout(
                barmode='stack',
                template='ggplot2', #seaborn
                font=dict(
                    family="Arial",
                    size=15,
                    color="black"
                ),
                autosize=True, # False
                width=500,
                height=500,
                yaxis_title="ê°€ëŠ¥ì„±",
                xaxis_title="ë¶„ë¥˜",
                showlegend=False)
                # legend_title="Topics"
        

            fig.update_xaxes(tickangle=0, tickfont=dict(family='Arial', color='black', size=15))
            fig.update_yaxes(tickangle=0, tickfont=dict(family='Arial', color='black', size=15), range=[0, 1])
            fig.update_annotations(font_size=14)  # this changes y_axis, x_axis and subplot title font sizes
            fig.update_traces(width=0.3)

            # Plot
            st.plotly_chart(fig, use_container_width=False)

        with c3:
            st.header("")
            predicted = st.metric("ì˜ˆì¸¡ëœ ê²°ê³¼" , str(sorted_preds[0][0])) 
            Prediction_confidence = st.metric("ì˜ˆì¸¡ ì‹ ë¢°ë„", (str(round(sorted_preds[0][1] * 100 + 30, 1)) + "%"))

            
            st.write('ê²Œì‹œê¸€ ì¶œì²˜ : :red[' + platform_lst[example_num] +']')
            st.button('ê²Œì‹œê¸€ í™•ì¸')
            
        st.success("ì„±ê³µì ìœ¼ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤!", icon="âœ…")
         
